tts --text "" --speaker_wav "Megan.wav" --language_idx 'en' --out_path "megan_10h30_output.wav" --model_name "tts_models/multilingual/multi-dataset/your_tts"

tts --model_path "/home/hannibal/overflow_ft/out/overflow_ljspeech-July-10-2023_05+59AM-eb61a8e/checkpoint_21000.pth" --config_path "/home/hannibal/overflow_ft/config.json" --list_language_idxs --list_speaker_idxs

tts --text "This is a test phrase to evaluate how much the learning rate influence the model performance over 500 and 1000 epochs, in each case the newer learning rate becomes 10 times the previous learning rate." --model_path /home/hannibal/overflow_ft/out/overflow_ljspeech-July-10-2023_05+59AM-eb61a8e/checkpoint_21000.pth --config_path /home/hannibal/overflow_ft/out/overflow_ljspeech-July-10-2023_05+59AM-eb61a8e/config.json --out_path ./audio/output_audio/testlr/1e-5_2100.wav --vocoder_name vocoder_models/en/ljspeech/hifigan_v2



print("[+] Testing the model with the learning rate 1e-3 and the checkpoint 21000")
tts --text $test_phrase --model_path /home/hannibal/overflow_ft/out/overflow_ljspeech-July-10-2023_05+59AM-eb61a8e/checkpoint_21000.pth --config_path /home/hannibal/overflow_ft/out/overflow_ljspeech-July-10-2023_05+59AM-eb61a8e/config.json --out_path $out_path"1e-3_21000.wav" --vocoder_name $vocoder_name

print("[+] Testing the model with the learning rate 1e-3 and the checkpoint 21500")
tts --text $test_phrase --model_path /home/hannibal/overflow_ft/out/overflow_ljspeech-July-10-2023_05+59AM-eb61a8e/checkpoint_21500.pth --config_path /home/hannibal/overflow_ft/out/overflow_ljspeech-July-10-2023_05+59AM-eb61a8e/config.json --out_path $out_path"1e-3_21500.wav" --vocoder_name $vocoder_name

print("[+] Testing the model with the learning rate 1e-2 and the checkpoint 21000")
tts --text $test_phrase --model_path /home/hannibal/overflow_ft/out/overflow_ljspeech-July-10-2023_05+59AM-eb61a8e/checkpoint_21000.pth --config_path /home/hannibal/overflow_ft/out/overflow_ljspeech-July-10-2023_05+59AM-eb61a8e/config.json --out_path $out_path"1e-2_21000.wav" --vocoder_name $vocoder_name

print("[+] Testing the model with the learning rate 1e-2 and the checkpoint 21500")
tts --text $test_phrase --model_path /home/hannibal/overflow_ft/out/overflow_ljspeech-July-10-2023_05+59AM-eb61a8e/checkpoint_21500.pth --config_path /home/hannibal/overflow_ft/out/overflow_ljspeech-July-10-2023_05+59AM-eb61a8e/config.json --out_path $out_path"1e-2_21500.wav" --vocoder_name $vocoder_name
 
 
 
 --restore_path /home/hannibal/.local/share/tts/tts_models--en--ljspeech--overflow/model_file.pth


 tts --help | tr '\n' ' '
usage: tts [-h] [--list_models [LIST_MODELS]]            [--model_info_by_idx MODEL_INFO_BY_IDX]            [--model_info_by_name MODEL_INFO_BY_NAME] [--text TEXT]            [--model_name MODEL_NAME] [--vocoder_name VOCODER_NAME]            [--config_path CONFIG_PATH] [--model_path MODEL_PATH]            [--out_path OUT_PATH] [--use_cuda USE_CUDA]            [--vocoder_path VOCODER_PATH]            [--vocoder_config_path VOCODER_CONFIG_PATH]            [--encoder_path ENCODER_PATH]            [--encoder_config_path ENCODER_CONFIG_PATH] [--emotion EMOTION]            [--speakers_file_path SPEAKERS_FILE_PATH]            [--language_ids_file_path LANGUAGE_IDS_FILE_PATH]            [--speaker_idx SPEAKER_IDX] [--language_idx LANGUAGE_IDX]            [--speaker_wav SPEAKER_WAV [SPEAKER_WAV ...]]            [--gst_style GST_STYLE]            [--capacitron_style_wav CAPACITRON_STYLE_WAV]            [--capacitron_style_text CAPACITRON_STYLE_TEXT]            [--list_speaker_idxs [LIST_SPEAKER_IDXS]]            [--list_language_idxs [LIST_LANGUAGE_IDXS]]            [--save_spectogram SAVE_SPECTOGRAM] [--reference_wav REFERENCE_WAV]            [--reference_speaker_idx REFERENCE_SPEAKER_IDX]            [--progress_bar PROGRESS_BAR] [--source_wav SOURCE_WAV]            [--target_wav TARGET_WAV] [--voice_dir VOICE_DIR]  Synthesize speech on command line.  You can either use your trained model or choose a model from the provided list.  If you don't specify any models, then it uses LJSpeech based English model.  ## Example Runs  ### Single Speaker Models  - List provided models:      $ tts --list_models  - Query info for model info by idx:      $ tts --model_info_by_idx "<model_type>/<model_query_idx>"  - Query info for model info by full name:      $ tts --model_info_by_name "<model_type>/<language>/<dataset>/<model_name>"  - Run TTS with default models:      $ tts --text "Text for TTS"  - Run a TTS model with its default vocoder model:      $ tts --text "Text for TTS" --model_name "<model_type>/<language>/<dataset>/<model_name>  - Run with specific TTS and vocoder models from the list:      $ tts --text "Text for TTS" --model_name "<model_type>/<language>/<dataset>/<model_name>" --vocoder_name "<model_type>/<language>/<dataset>/<model_name>" --output_path  - Run your own TTS model (Using Griffin-Lim Vocoder):      $ tts --text "Text for TTS" --model_path path/to/model.pth --config_path path/to/config.json --out_path output/path/speech.wav  - Run your own TTS and Vocoder models:     $ tts --text "Text for TTS" --model_path path/to/config.json --config_path path/to/model.pth --out_path output/path/speech.wav         --vocoder_path path/to/vocoder.pth --vocoder_config_path path/to/vocoder_config.json  ### Multi-speaker Models  - List the available speakers and choose as <speaker_id> among them:      $ tts --model_name "<language>/<dataset>/<model_name>"  --list_speaker_idxs  - Run the multi-speaker TTS model with the target speaker ID:      $ tts --text "Text for TTS." --out_path output/path/speech.wav --model_name "<language>/<dataset>/<model_name>"  --speaker_idx <speaker_id>  - Run your own multi-speaker TTS model:      $ tts --text "Text for TTS" --out_path output/path/speech.wav --model_path path/to/config.json --config_path path/to/model.pth --speakers_file_path path/to/speaker.json --speaker_idx <speaker_id>  ### Voice Conversion Models      $ tts --out_path output/path/speech.wav --model_name "<language>/<dataset>/<model_name>" --source_wav <path/to/speaker/wav> --target_wav <path/to/reference/wav>       optional arguments:   -h, --help            show this help message and exit   --list_models [LIST_MODELS]                         list available pre-trained TTS and vocoder models.   --model_info_by_idx MODEL_INFO_BY_IDX                         model info using query format: <model_type>/<model_query_idx>   --model_info_by_name MODEL_INFO_BY_NAME                         model info using query format: <model_type>/<language>/<dataset>/<model_name>   --text TEXT           Text to generate speech.   --model_name MODEL_NAME                         Name of one of the pre-trained TTS models in format <language>/<dataset>/<model_name>   --vocoder_name VOCODER_NAME                         Name of one of the pre-trained  vocoder models in format <language>/<dataset>/<model_name>   --config_path CONFIG_PATH                         Path to model config file.   --model_path MODEL_PATH                         Path to model file.   --out_path OUT_PATH   Output wav file path.   --use_cuda USE_CUDA   Run model on CUDA.   --vocoder_path VOCODER_PATH                         Path to vocoder model file. If it is not defined, model uses GL as vocoder. Please make sure that you installed vocoder library before (WaveRNN).   --vocoder_config_path VOCODER_CONFIG_PATH                         Path to vocoder model config file.   --encoder_path ENCODER_PATH                         Path to speaker encoder model file.   --encoder_config_path ENCODER_CONFIG_PATH                         Path to speaker encoder config file.   --emotion EMOTION     Emotion to condition the model with. Only available for üê∏Coqui Studio models.   --speakers_file_path SPEAKERS_FILE_PATH                         JSON file for multi-speaker model.   --language_ids_file_path LANGUAGE_IDS_FILE_PATH                         JSON file for multi-lingual model.   --speaker_idx SPEAKER_IDX                         Target speaker ID for a multi-speaker TTS model.   --language_idx LANGUAGE_IDX                         Target language ID for a multi-lingual TTS model.   --speaker_wav SPEAKER_WAV [SPEAKER_WAV ...]                         wav file(s) to condition a multi-speaker TTS model with a Speaker Encoder. You can give multiple file paths. The d_vectors is computed as their average.   --gst_style GST_STYLE                         Wav path file for GST style reference.   --capacitron_style_wav CAPACITRON_STYLE_WAV                         Wav path file for Capacitron prosody reference.   --capacitron_style_text CAPACITRON_STYLE_TEXT                         Transcription of the reference.   --list_speaker_idxs [LIST_SPEAKER_IDXS]                         List available speaker ids for the defined multi-speaker model.   --list_language_idxs [LIST_LANGUAGE_IDXS]                         List available language ids for the defined multi-lingual model.   --save_spectogram SAVE_SPECTOGRAM                         If true save raw spectogram for further (vocoder) processing in out_path.   --reference_wav REFERENCE_WAV                         Reference wav file to convert in the voice of the speaker_idx or speaker_wav   --reference_speaker_idx REFERENCE_SPEAKER_IDX                         speaker ID of the reference_wav speaker (If not provided the embedding will be computed using the Speaker Encoder).   --progress_bar PROGRESS_BAR                         If true shows a progress bar for the model download. Defaults to True   --source_wav SOURCE_WAV                         Original audio file to convert in the voice of the target_wav   --target_wav TARGET_WAV                         Target audio file to convert in the voice of the source_wav   --voice_dir VOICE_DIR                         Voice dir for tortoise model